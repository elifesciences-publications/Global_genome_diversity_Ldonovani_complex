library(data.table)
library(ggplot2)
library(ade4)
setwd("~/work/Leish_donovaniComplex/MS01_globalDiversity_Ldonovani/github_scripts/02_IBD_analysis/")
#-----------------------------
# functions
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL)
{
library(grid)
# Make a list from the ... arguments and plotlist
plots <- c(list(...), plotlist)
numPlots = length(plots)
# If layout is NULL, then use 'cols' to determine layout
if (is.null(layout)) {
# Make the panel
# ncol: Number of columns of plots
# nrow: Number of rows needed, calculated from # of cols
layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
ncol = cols, nrow = ceiling(numPlots/cols))
}
if (numPlots==1) {
print(plots[[1]])
} else {
# Set up the page
grid.newpage()
pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
# Make each plot, in the correct location
for (i in 1:numPlots) {
# Get the i,j matrix positions of the regions that contain this subplot
matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
layout.pos.col = matchidx$col))
}
}
}
ReplaceLowerOrUpperTriangle <- function(m, triangle.to.replace)
{
# If triangle.to.replace="lower", replaces the lower triangle of a square matrix with its upper triangle.
# If triangle.to.replace="upper", replaces the upper triangle of a square matrix with its lower triangle.
if (nrow(m) != ncol(m)) stop("Supplied matrix must be square.")
if      (tolower(triangle.to.replace) == "lower") tri <- lower.tri(m)
else if (tolower(triangle.to.replace) == "upper") tri <- upper.tri(m)
else stop("triangle.to.replace must be set to 'lower' or 'upper'.")
m[tri] <- t(m)[tri]
return(m)
}
GeoDistanceInMetresMatrix <- function(df.geopoints)
{
# Returns a matrix (M) of distances between geographic points.
# M[i,j] = M[j,i] = Distance between (df.geopoints$lat[i], df.geopoints$lon[i]) and
# (df.geopoints$lat[j], df.geopoints$lon[j]).
# The row and column names are given by df.geopoints$name.
GeoDistanceInMetres <- function(g1, g2){
# Returns a vector of distances. (But if g1$index > g2$index, returns zero.)
# The 1st value in the returned vector is the distance between g1[[1]] and g2[[1]].
# The 2nd value in the returned vector is the distance between g1[[2]] and g2[[2]]. Etc.
# Each g1[[x]] or g2[[x]] must be a list with named elements "index", "lat" and "lon".
# E.g. g1 <- list(list("index"=1, "lat"=12.1, "lon"=10.1), list("index"=3, "lat"=12.1, "lon"=13.2))
DistM <- function(g1, g2){
require("Imap")
return(ifelse(g1$index > g2$index, 0, gdist(lat.1=g1$lat, lon.1=g1$lon, lat.2=g2$lat, lon.2=g2$lon, units="km")))
}
return(mapply(DistM, g1, g2))
}
n.geopoints <- nrow(df.geopoints)
# The index column is used to ensure we only do calculations for the upper triangle of points
df.geopoints$index <- 1:n.geopoints
# Create a list of lists
list.geopoints <- by(df.geopoints[,c("index", "lat", "lon")], 1:n.geopoints, function(x){return(list(x))})
# Get a matrix of distances (in metres)
mat.distances <- ReplaceLowerOrUpperTriangle(outer(list.geopoints, list.geopoints, GeoDistanceInMetres), "lower")
# Set the row and column names
rownames(mat.distances) <- df.geopoints$name
colnames(mat.distances) <- df.geopoints$name
return(mat.distances)
}
adj_name_notation<-function(old_name)
{
old_name<-as.character(old_name)
old_name[startsWith(old_name, "X")]<-gsub("X", "", old_name[startsWith(old_name, "X")])
old_name<-gsub("\\.", "-", old_name)
old_name<-gsub("BHU1062-4", "BHU1062_4", old_name)
old_name<-gsub("LRC_L1303", "LRC-L1303", old_name)
old_name<-gsub("LRC_L47", "LRC-L47", old_name)
}
manteltest_for_samps<-function(all, samps, nperm)
{
sub_Neisd<-Neisd_m[sample %in% samps, colnames(Neisd_m) %in% samps, with=F]
sub_sampdist<-samp_dist_m[sample %in% samps, colnames(samp_dist_m) %in% samps, with=F]
print(dim(sub_Neisd))
# mantel.rtest(as.dist(sub_Neisd),as.dist(sub_sampdist),nrepet = 100)
mantel.randtest(as.dist(sub_Neisd),as.dist(sub_sampdist),nrepet = nperm)
}
mantel_summary<-function(name, res)
{
c(group=name, correlation=res$obs, pvalue=res$pvalue, res$expvar, nperm=res$rep)
}
#-----------------------------
# load geographical coordinates of the sampling locations
coord<-data.table(read.table("TableS1_coordinates.txt", header = T))
setnames(coord,colnames(coord)[c(1,5,6)],c("name","lat","lon"))
coord[,name:=as.character(name)]
coord<-coord[order(name)]
coord[, name:=gsub("Ldon282CL4", "Ldon282cl2", name)]
# calulate geographical distances between sampling locations
samp_dist_m<-GeoDistanceInMetresMatrix(coord[,c(1,5,6)])
samp_dist<-data.table(reshape2::melt(samp_dist_m))
setnames(samp_dist,colnames(samp_dist),c("samp1","samp2","dist"))
# load weighted NeisD that was also used to build the tree
Neisd_m<-data.table(read.table("../01_phylogenetic_reconstruction/NeisD/LmjF.allchr.weighted_NeisD.ind_NA.frac0.2_dphC.txt"))
setnames(Neisd_m,colnames(Neisd_m),c("sample",as.character(Neisd_m$V1)))
#
Neisd_m
# adjust name notation to match distance matrix
Neisd_m$sample<-adj_name_notation(Neisd_m$sample)
colnames(Neisd_m)<-adj_name_notation(colnames(Neisd_m))
#
Neisd<-melt(Neisd_m, id.vars = "sample")
setnames(Neisd,colnames(Neisd),c("samp1","samp2","NeisD"))
Neisd<-Neisd[order(samp1,samp2)]
# check that sample names between genetic and geographic distances match
comp_names<-data.table(cbind(unique(Neisd$samp1),as.character(unique(samp_dist$samp1))))
comp_names[V1!=V2]
all<-merge(Neisd,samp_dist)
all[,samp1:=as.character(samp1)]
all[,samp2:=as.character(samp2)]
all[, samp1_species:=unlist(lapply(all$samp1, function(x) coord[name==x, Leish_species]))]
all[, samp2_species:=unlist(lapply(all$samp2, function(x) coord[name==x, Leish_species]))]
all[, samp1_group:=unlist(lapply(all$samp1, function(x) coord[name==x, Leish_group]))]
all[, samp2_group:=unlist(lapply(all$samp2, function(x) coord[name==x, Leish_group]))]
all[, samp1_group_colour:=unlist(lapply(all$samp1, function(x) coord[name==x, Leish_group_colour]))]
all[, samp2_group_colour:=unlist(lapply(all$samp2, function(x) coord[name==x, Leish_group_colour]))]
all[,comb_group:=paste(samp1_group,samp2_group, sep="_")]
all[samp1_species!=samp2_species,comp_species:="both"]
all[samp1_species==samp2_species & samp1_species=="L.infantum",comp_species:="Linf"]
all[samp1_species==samp2_species & samp1_species=="L.donovani",comp_species:="Ldon"]
all<-all[order(samp1_group, samp2_group)]
# Linf core definition
all[,Linf_Mon1:=F]
all[samp1_group %in% c("Linf1") & samp2_group %in% c("Linf1"),Linf_Mon1:=T]
all[samp1 %in% c("Inf152","WR285","Inf045","LRC-L47","Inf055","Inf004") | samp2 %in% c("Inf152","WR285","Inf045","LRC-L47","Inf055","Inf004"),Linf_Mon1:=F]
#
# prepare data for Mantel test
Neisd_m
samp_dist_m
#
samp_dist_m<-GeoDistanceInMetresMatrix(coord[,c(1,5,6)])
a<-colnames(samp_dist_m)
samp_dist_m<-data.table(samp_dist_m)
samp_dist_m[,sample:=a]
setcolorder(samp_dist_m, c("sample",sort(a)))
samp_dist_m<-samp_dist_m[order(sample)]
#
setcolorder(Neisd_m, c("sample",sort(a)))
Neisd_m<-Neisd_m[order(sample)]
# check sample names and orders are identical
sum(colnames(Neisd_m)!=colnames(samp_dist_m))
# [1] 0
sum(Neisd_m$sample!=samp_dist_m$sample)
# [1] 0
ggplot(all, aes(dist, NeisD)) +
geom_point() +
facet_grid(samp1_species~samp2_species)
Ldon_gg<-ggplot(all[comp_species=="Ldon"], aes(dist, NeisD)) +
geom_point() + geom_smooth(method='lm',formula=y~x) +
labs(title=expression(paste(italic("L. donovani"), " all")), x="Distance [km]")# + theme_update(plot.title = element_text(hjust = 0.5))
Ldon_mantel<-manteltest_for_samps(all, unique(c(all[comp_species=="Ldon",samp1],all[comp_species=="Ldon",samp2])), 10000)
##########
# Ldon
Ldon_gg<-ggplot(all[comp_species=="Ldon"], aes(dist, NeisD)) +
geom_point() + geom_smooth(method='lm',formula=y~x) +
labs(title=expression(paste(italic("L. donovani"), " all")), x="Distance [km]")# + theme_update(plot.title = element_text(hjust = 0.5))
ggplot(all[comp_species=="Ldon"], aes(dist, NeisD)) +
geom_point() + geom_smooth(method='lm',formula=y~x) +
labs(title=expression(paste(italic("L. donovani"), " all")), x="Distance [km]")#
Ldon_mantel<-manteltest_for_samps(all, unique(c(all[comp_species=="Ldon",samp1],all[comp_species=="Ldon",samp2])), 10000)
Ldon_mantel
library(foreach)
library(data.table)
library(ggplot2)
library(GGally)
library(gridExtra)
setwd("~/work/Leish_donovaniComplex/MS01_globalDiversity_Ldonovani/github_scripts/04_aneuploidy")
# # data tables tht will be created
# ploidy        # sample ploidies in different columns
# ploidy.a      # sample ploidies in one column along with meta data
# sample.info   # sample info including groups and colours
# sd.g          # sd in somy by chromosome and group, in different columns for different groups
# sd.g.format   # sd in somy by chromosome and group along with metadata, i.e. group
# generate and safe file with sample metadata information
#
# load(file=paste0(path,"/leish_donovaniComplex/A05_heterozygosities/sample.info.RData"))
# sample.info[groups=="infantum1", groups:="Linf1"]
# sample.info[groups=="donovani1", groups:="Ldon1"]
# sample.info[groups=="donovani3", groups:="Ldon5"]
# sample.info[groups=="donovani2", groups:="Ldon4"]
# sample.info[groups=="donovani4", groups:="Ldon3"]
# sample.info[grep("CUK", sample), groups:="CUK_Linf"]
# sample.info[grep("CUK", sample), group.col:="green"]
# sample.info[grep("CH", sample), groups:="CH_Linf"]
# sample.info[grep("CH", sample), group.col:="gray34"]
# sample.info[sample %in% c("EP","MAM"), groups:="other_Linf"]
# sample.info[sample %in% c("EP","MAM"), group.col:="black"]
# sample.info[sample %in% c("GE","LEM3472","LRC.L740"), groups:="other_Ldon"]
# sample.info[sample %in% c("GE","LEM3472","LRC.L740"), group.col:="#ff0080"]
# sample.info[sample %in% c("BPK156A1","BPK406A1","BPK413A1","BPK512A1","BPK612A1","BPK623A1","BPK648A1"), groups:="Ldon2"]
# sample.info[sample %in% c("BPK156A1","BPK406A1","BPK413A1","BPK512A1","BPK612A1","BPK623A1","BPK648A1"), group.col:="#7300da"]
#
# table(sample.info$groups)
# # CH        CUK      Ldon1      Ldon2      Ldon3      Ldon4      Ldon5      Linf1 other_Ldon other_Linf
# # 5         11         45          7         19          4          8         47          3          2
#
# save(sample.info, file="../01_phylogenetic_reconstruction/sample.info_NEWsubgroups.RData")
load(file="../01_phylogenetic_reconstruction/sample.info_NEWsubgroups.RData") # sample.info
ploidy<-data.table(read.table("somies_updated.txt", header = T))
######################
# functions
# reorder correlation matrix
reorder.cor.mat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
cormat
}
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
cormat[lower.tri(cormat)] <- NA
return(cormat)
}
get_upper_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# The F statistic on the last line is telling you whether the regression as a whole
# is performing 'better than random' - any set of random predictors will have some
# relationship with the response, so it's seeing whether your model fits better than you'd
# expect if all your predictors had no relationship with the response (beyond what would
# be explained by that randomness). This is used for a test of whether the model outperforms
# 'noise' as a predictor. The p-value in the last row is the p-value for that test,
# essentially comparing the full model you fitted with an intercept-only model.
#
# method for getting the overall pval of the regression model
lmp <- function (modelobject) {
if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
f <- summary(modelobject)$fstatistic
p <- pf(f[1],f[2],f[3],lower.tail=F)
attributes(p) <- NULL
return(p)
}
oidy.a<-cbind(ploidy)
ploidy.a<-melt(ploidy.a, measure.vars = colnames(ploidy))
ploidy.a[,chr:=rep(1:36, ncol(ploidy))]
setnames(ploidy.a, colnames(ploidy.a)[1:2], c("sample","somy"))
for (i in unique(sample.info$groups)) {
ploidy.a[sample %in% sample.info[groups==i, sample],group:=i]
}
ploidy.a[,size:=length(sample)/36, by=(group)] # size of the group
ploidy.a[,c:=1]
ploidy.a[,c_somy.chr.g:=sum(c), by=.(group, somy, chr)] # counts for each somy per chr and per group
ploidy.a[,sd_somy.chr.g:=sd(somy), by=.(group, chr)]
ploidy.a[,sd_somy.chr:=sd(somy), by=.(chr)]
ploidy.a[,med_somy.chr:=median(somy), by=.(chr)]
ploidy.a[,mean_somy.chr:=mean(somy), by=.(chr)]
ploidy.a[,mean_somy.chr.g:=mean(somy), by=.(group,chr)]
ploidy.a[size>=9,med_somy.chr.g:=median(somy), by=.(group,chr)]
color.palette  <- c(colorRampPalette(c("yellow","orange","green4","blue","red"))(6) ,c("purple","pink"))
library(foreach)
library(data.table)
library(ggplot2)
library(GGally)
library(gridExtra)
setwd("~/work/Leish_donovaniComplex/MS01_globalDiversity_Ldonovani/github_scripts/04_aneuploidy")
# sample.info[sample %in% c("GE","LEM3472","LRC.L740"), groups:="other_Ldon"]
# sample.info[sample %in% c("GE","LEM3472","LRC.L740"), group.col:="#ff0080"]
# sample.info[sample %in% c("BPK156A1","BPK406A1","BPK413A1","BPK512A1","BPK612A1","BPK623A1","BPK648A1"), groups:="Ldon2"]
# sample.info[sample %in% c("BPK156A1","BPK406A1","BPK413A1","BPK512A1","BPK612A1","BPK623A1","BPK648A1"), group.col:="#7300da"]
#
# table(sample.info$groups)
# # CH        CUK      Ldon1      Ldon2      Ldon3      Ldon4      Ldon5      Linf1 other_Ldon other_Linf
# # 5         11         45          7         19          4          8         47          3          2
#
# save(sample.info, file="../01_phylogenetic_reconstruction/sample.info_NEWsubgroups.RData")
load(file="../01_phylogenetic_reconstruction/sample.info_NEWsubgroups.RData") # sample.info
ploidy<-data.table(read.table("somies_updated.txt", header = T))
setwd("~/work/Leish_donovaniComplex/MS01_globalDiversity_Ldonovani/github_scripts/04_aneuploidy")
getwd()
setwd("~/work/Leish_donovaniComplex/MS01_globalDiversity_Ldonovani/github_scripts/Global_genome_diversity_Ldonovani_complex/04_aneuploidy/")
ploidy<-data.table(read.table("somies_updated.txt", header = T))
# reorder correlation matrix
reorder.cor.mat <- function(cormat){
# Use correlation between variables as distance
dd <- as.dist((1-cormat)/2)
hc <- hclust(dd)
cormat <-cormat[hc$order, hc$order]
cormat
}
# Get lower triangle of the correlation matrix
get_lower_tri<-function(cormat){
cormat[lower.tri(cormat)] <- NA
return(cormat)
}
get_upper_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# The F statistic on the last line is telling you whether the regression as a whole
# is performing 'better than random' - any set of random predictors will have some
# relationship with the response, so it's seeing whether your model fits better than you'd
# expect if all your predictors had no relationship with the response (beyond what would
# be explained by that randomness). This is used for a test of whether the model outperforms
# 'noise' as a predictor. The p-value in the last row is the p-value for that test,
# essentially comparing the full model you fitted with an intercept-only model.
#
# method for getting the overall pval of the regression model
lmp <- function (modelobject) {
if (class(modelobject) != "lm") stop("Not an object of class 'lm' ")
f <- summary(modelobject)$fstatistic
p <- pf(f[1],f[2],f[3],lower.tail=F)
attributes(p) <- NULL
return(p)
}
#######################
#
#
ploidy.a<-cbind(ploidy)
ploidy.a<-melt(ploidy.a, measure.vars = colnames(ploidy))
ploidy.a[,chr:=rep(1:36, ncol(ploidy))]
setnames(ploidy.a, colnames(ploidy.a)[1:2], c("sample","somy"))
for (i in unique(sample.info$groups)) {
ploidy.a[sample %in% sample.info[groups==i, sample],group:=i]
}
ploidy.a[,size:=length(sample)/36, by=(group)] # size of the group
ploidy.a[,c:=1]
ploidy.a[,c_somy.chr.g:=sum(c), by=.(group, somy, chr)] # counts for each somy per chr and per group
ploidy.a[,sd_somy.chr.g:=sd(somy), by=.(group, chr)]
ploidy.a[,sd_somy.chr:=sd(somy), by=.(chr)]
ploidy.a[,med_somy.chr:=median(somy), by=.(chr)]
ploidy.a[,mean_somy.chr:=mean(somy), by=.(chr)]
ploidy.a[,mean_somy.chr.g:=mean(somy), by=.(group,chr)]
ploidy.a[size>=9,med_somy.chr.g:=median(somy), by=.(group,chr)]
color.palette  <- c(colorRampPalette(c("yellow","orange","green4","blue","red"))(6) ,c("purple","pink"))
ggplot(data=ploidy.a, aes(x=as.factor(chr), y=somy, color=as.factor(med_somy.chr))) +
geom_boxplot(fatten = 5) +
labs(x = "Chromosome", y = "Somy", color = "Median\nsomy") +
scale_color_manual(values=color.palette[sort(unique(ploidy.a$med_somy.chr))])
ploidy.a[,.(chr, group,mean_somy.chr,mean_somy.chr.g)][chr==1 & group=="Linf1"]
# somy variability by chromosome
#
xx<-unique(ploidy.a[,.(chr,group,size,med_somy.chr,mean_somy.chr.g,sd_somy.chr.g)])[size>=9]
xx[,med_sd_somy.chr.g:=median(sd_somy.chr.g), by=.(chr)]
xx[,med_mean_somy.chr.g:=median(mean_somy.chr.g), by=.(chr)]
#
xx[,chr:=as.factor(chr)]
xx$chr <- factor(xx$chr, levels = unique(xx[,.(chr,med_sd_somy.chr.g)])[order(med_sd_somy.chr.g)]$chr) # sorting chr levels accoring to the median of the group sd in somy
#
ggplot(data=xx[size>=9], aes(as.factor(chr), y=sd_somy.chr.g, fill=as.factor(med_somy.chr))) +
geom_boxplot() +
labs(x="Chromosomes [ordered by median sd of group somies]",
y="Sd of somies of the four largest groups") +
guides(fill=guide_legend(title="Median\nsomy across\n151 samples")) +
theme(legend.position="none") +
scale_fill_manual(values=color.palette[unique(ploidy.a$med_somy.chr)])
xx.red<-xx[size>=9][, sd_somy.chr.g.med:=median(sd_somy.chr.g), by=chr]
xx.red<-unique(xx.red[,.(chr, sd_somy.chr.g.med)])
xx$chr <- factor(xx$chr, levels = unique(xx[,.(chr,med_mean_somy.chr.g)])[order(med_mean_somy.chr.g)]$chr)
xx$chr <- factor(xx$chr, levels = 1:36) # sorting chr levels by chr number again
# correlation between sd in population somy
sd.g.format<-unique(xx[size>=9][,.(chr, group, sd_somy.chr.g, med_sd_somy.chr.g)])
sd.g<-dcast(sd.g.format, chr ~ group, value.var = "sd_somy.chr.g")
plot(sd.g[,2:5, with=F])
cor(sd.g[,2:5, with=F], method = "spearman")
pvals<-cor.test(unlist(sd.g[,2, with=F]), unlist(sd.g[,3, with=F]))$p.value
pvals<-c(pvals, cor.test(unlist(sd.g[,2, with=F]), unlist(sd.g[,4, with=F]))$p.value)
pvals<-c(pvals, cor.test(unlist(sd.g[,2, with=F]), unlist(sd.g[,5, with=F]))$p.value)
pvals<-c(pvals, cor.test(unlist(sd.g[,3, with=F]), unlist(sd.g[,4, with=F]))$p.value)
pvals<-c(pvals, cor.test(unlist(sd.g[,3, with=F]), unlist(sd.g[,5, with=F]))$p.value)
pvals<-c(pvals, cor.test(unlist(sd.g[,4, with=F]), unlist(sd.g[,5, with=F]))$p.value)
p.adjust(pvals)
cor.test()
?cor.test
